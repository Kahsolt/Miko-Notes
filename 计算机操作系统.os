考研复习：计算机操作系统

零.操作系统概览
1.基本概念
特征
  并发	引入进程的目的，微观分时交替；甚至并行(多流水线/多处理器)
  共享	互斥共享(分时不交替)/同时共享(分时可交替)
  虚拟	时分复用/空分复用
  异步	保证时序的任意性不影响函数结果的一致性
目标和功能
  资源管理
    处理机管理	可归结为进程管理(处理机的分配以进程为单位)：进程生命周期控制、进程间同步/通信、死锁处理、处理机调度
    存储器管理	内存分配、地址映射、内存保护/共享、内存扩充
    文件管理	文件存储空间管理、目录管理、文件读写/权限控制管理
    设备管理	缓冲管理、设备分配、设备处理、虚拟设备
  硬件-用户接口
    命令接口
      联机/交互式命令接口	一组键盘操作命令，控制权在系统与控制台间轮流切换
      脱机/批处理命令接口	预先写好的批处理脚本，中途无法干预程序
    程序接口
      系统调用			用户在程序中的操作间接使用系统调用命令
  虚拟机：资源封装虚拟化，扩充机器功能

2.发展分类
手工操作阶段/无操作系统
  程序从装入、运行、结果，所有工作都需人工干预；单用户独占全机
批处理阶段
  *核心：监督程序+批处理脚本
  单道批处理
    自动	作业间切换无需人工干预
    顺序	各作业串行地顺序启动、顺序完成
    单道	监督程序保证内存中只有一道作业，完成或异常退出后切入新作业
  多道批处理
    多道	内存中驻留多道作业，共享软硬件资源，监督程序调度作业运行状态/分配CPU及资源
    宏观并行	可以有多道作业都在运行态
    微观串行	轮流使用CPU
分时操作系统
  *核心：时间片轮转
  同时/多路	多个终端上的用户可同时使用计算机
  交互		可人机对话，控制程序运行的细节
  独立		用户间感知隔离，不受他者影响
  及时		用户请求的响应迅速
实时操作系统
  *核心：外部信号产生后能够实时应对，且在规定时间内完成
网络操作系统
  *核心：多个物理机网络起来实现软硬件的资源共享，但单机完成一件工作；终端用户需要了解一定的物理拓扑，知道所需资源的所在位置
分布式操作系统
  *核心：多个物理设备在逻辑上构成一个模型系统，若干物理机协作完成同一件事；终端用户不用在意实际物理机的拓扑架构
个人计算机操作系统
嵌入式操作系统
服务器操作系统
多处理器操作系统

3.运行环境
内核机制
  时钟管理	计时/中断
  中断机制	进程调度/系统调用/外设输入输出
  原语		原子操作(Atomic Operation)，系统底层被频繁调用的不可打断的公共小程序(定义原语的常用方法：关中断)
  系统数据结构	系统登记表(作业控制块/进程控制块/设备控制块/消息队列/缓冲区/内存分配表)，用于进程/存储器/设备管理
中断/异常
  门：内核提供的机制，使得用户程序能陷入内核
  态：PSW中有一位区分目态和管态
系统调用
  分类：设备管理/文件管理/进程控制/进程通信/内存管理
  管目切换的情况
    1.用户程序代码中的系统调用
    2.发生一次中断
    3.用户程序运行时错误
    4.用户程序企图执行特权指令
    5.核心态转回用户态时的特权指令IRET

4.体系结构
宏内核	内核-服务打包为一个二进制，接口复杂
微内核	分离内核-服务/服务-服务，瓶颈在IPC

一.进程管理
1.进程
概念：程序的一次执行过程，资源分配和调度的独立单位
特征
  动态	进程生命周期内在各个状态间迁移
  并发	同一时间段内多个进程协进
  独立	独立调运运行、获取资源的单位
  异步	程序间断执行，进程完成度不同步
  结构	=PCB+程序段+数据段
状态
    创建-->就绪<-->运行-->终止
              \    /
               阻塞
  创建	申请空白PCB，填入程序和管理信息，分配运行时资源，资源充足则转入就绪态
  就绪	其他资源已足，只缺处理机
  运行	获得处理机，程序正常跑
  阻塞	运行期间因缺处理机外的某资源而被迫等待
  结束	程序正常退出或异常终止，释放回收资源撤销PBC
转换
  就绪->运行	被调度为当前进程获得处理机
  运行->就绪	时间片到期中断/高优先级任务抢断
  运行->阻塞	等待资源事件而无法行进，进程切出
  阻塞->就绪	所等待的资源被分配，如I/O结束或中断处理结束
控制
  创建：父进程通过系统调用创建子进程
    1.分配新的进程标志号，申请空白PCB(申请失败则创建失败)
    2.分配用户栈等内存资源(申请失败则切为阻塞状态)
    3.初始化PCB控制信息，如标志信息、处理机(寄存器)信息、优先级
    4.插入就绪队列等待调度
  终止：程序正常结束/异常终止；用户强制结束
    1.根据PID检索PCB，读出进程状态
    2.若进程处于运行态则修改为终止态，让出处理机资源；若该进程有子进程，递归修改为终止态
    3.将该进程及其子进程的全部资源返还给父进程或操作系统
    4.递归地从相应的队列中删除PCB
  阻塞
    1.根据PID检索PCB，读出进程状态
    2.若进程处于运行态则修改为阻塞态，保存现场到PCB中
    3.PCB移入阻塞队列
  唤醒
    1.根据PID检索PCB，读出进程状态
    2.若进程处于阻塞态则修改为就绪态
    3.PCB移入就绪队列
  切换
    1.转储各种寄存器到PCB，更新状态信息
    2.PCB迁移到合适的队列
    3.就绪队列中选择一个进程，修改状态信息
    4.恢复PCB中的信息到处理机，让权
组织
  进程控制块PCB
    实现：常驻内存，按不同进程状态分为多个链表队列/索引表
    字段
      进程描述信息	进程标识符PID/用户标识符UID
      进程控制管理信息	进程状态/优先级/代码运行入口地址/外存地址/进入内存时间/处理机占用时间/信号量使用
      资源分配清单	代码段指针/数据段指针/堆栈段指针/文件描述符/键盘/鼠标
      处理机转储		通用寄存器/地址寄存器/控制寄存器/标志寄存器/程序状态字PSW
  程序段：多个进程可以共享一个程序段
  数据段：可以是程序载入时的原始rodata，也可以是执行间产生的暂存数据
通信
  共享存储：进程间通过系统调用获取一块共享的读写空间，使用PV操作以同步
  消息传递：数据封装为消息Message，操作系统提供收发消息的原语
    直接	把发送方的消息挂到接收方的消息队列上，接收方从自己的PCB消息队列里取
    间接/信箱	发送方消息送入中间实体信箱，接收方从信箱里取
  管道通信：半双工读写的pipe文件，满时阻塞write()空时阻塞read()，是一个内存缓冲区(Linux上4KB)

2.线程
概念：CPU执行单元，独立调度和分派的基本单位，=线程ID+寄存器转储+堆栈，没有自己的系统资源
线进程对比
  调度	线程是CPU调度的单位，进程是其余资源的分配单位
  资源	线程不持有其余资源，而是访问其从所属进程的资源
  并发	线程间也可以协进，一个进程可以占用多个处理机核心
  地址	进程间地址空间独立，线程间共享地址空间
  通信	进程间通信IPC必须进程同步和互斥辅助手段等，线程间通信可以直接读写数据段(作为全局变量)
属性
  1.轻量化进程，不拥有系统资源，有TID和TCB(记录寄存器转储)
  2.不同线程可以执行相同程序，例如服务进程产生若干个处理线程
  3.同一个进程下的线程共享资源
  4.多核心处理机系统中多个线程可以占用多个处理器，导致进程处理时间缩短
  5.线程也有不同的状态和状态迁移，此时进程状态的意义重定义为其下线程的状态
实现方式
  用户级线程ULT		用户程序调用线程库，在切面上由库进行进线程转换，内核意识不到线程的存在
  内核级线程KLT		内核以线程为调度单位、管理维护各上下文，暴露给用户程序系统调用的线程相关接口
多线程模型
  多对一	多个用户级线程任务映射为一个内核级线程，用户线程管理在用户空间完成；任意线程阻塞都会阻塞进程，即伪多线程
  一对一	任何用户级线程阻塞不影响其他线程，但相应的创建内核线程开销较大
  多对多	n个用户级线程映射为m个内核级线程(m<=n)

3.处理机调度
概念：程序多处理机少，需要设计方法以公平分配处理机
调度层次
  高级/作业调度		选取外存中的后备作业、分配资源、建立进程，每个作业只调入调出一次；一般几分钟一次
  中级/内存调度		长时间阻塞的程序调入外存暂时挂起以腾出内存，合适时再调回内存
  低级/进程调度		从就绪队列中重新选当前程序；一般每几十毫秒一次
调度的时机
  不合适
    1.正在处理中断
    2.正在系统内核的临界区
    3.其他需要屏蔽中断的原子性场合
  合适
    1.当前进程无法继续，则可切出(非剥夺)
    2.中断或自陷处理结束，若请求调度标志有效，则可马上进行进程调度(剥夺)
调度方式
  非剥夺	获得CPU后就可执行到时间片完或因阻塞而等待为止
  剥夺		可以强制暂停正在运行的进程，切换到更紧迫的任务
调度的准则
  CPU利用率	尽可能让CPU忙
  系统吞吐量	单位时间完成作业数，短作业多则吞吐量大
  周转时间	＝作业完成时间-作业提交时间；带权周转时间＝周转时间/作业实际运行时间(CPU时间)
  等待时间	在等待队列中的时间和
  响应时间	从用户提交请求到首次产生响应的时间
调度算法
  先来先服务FCFS	利于长作业、CPU繁忙型作业；不利于短作业、I/O繁忙型作业
  短作业优先SJF		长作业饥饿现象、不保证实时性；平均等待、周转时间最短
  优先级		用于作业/进程调度；剥夺式／非剥夺式、静态优先级/动态优先级
  高响应比优先		响应比Rp=(等待时间+要求服务时间)/要求服务时间；兼顾长短作业，克服饥饿
  时间片轮转RR		先来先服务、但每次仅运行一个时间片，超时后被剥夺重新排队
  多级反馈队列		多个队列优先级递降、时间片递增，新增进程加入第一级队列按FCFS排队，一次执行后未完成则降入下一级队列
  
4.进程同步
概念
  临界资源	一次仅允许一个进程访问的资源
  同步/直接制约	为完成同一个任务而建立多个进程，在某些位置上需协调工作次序、等待合作进程传递数据
  互斥/间接制约	多个不相干进程争用公共的互斥资源
  *准则：空闲让进、忙则等待、有限等待、让权等待
实现临界区互斥的方法
  软件实现
    单标志法：多个进程按照预定轮次轮流进入临界区，全局变量turn指明了当前允许进入临界区的进程编号
      Pi:			Pj:
        while(turn!=i);		  while(trun!=j);	// 等待轮到自己
        // critical code	  // critical code
        turn=j;			  turn=i;		// 让权给第i号进程
    双标志法先检查：等待特定进程离开然后宣言进入临界区后进入临界区；此方法可能导致多个进程进入临界区!
      Pi:			Pj:
        while(flag[j]);		  while(flag[i]);	// 等待特定进程放权
        flag[i]=true;		  flag[j]=true;		// 宣言自己进入临界区
        // critical code	  // critical code
        flag[i]=false;		  flag[j]=false;
    双标志法后检查：宣言进入临界区后等待特定进程离开然后进入临界区；此方法可能导致谁也无法进入临界区的饥饿!
      Pi:                       Pj:
        flag[i]=true;             flag[j]=true;         // 宣言自己进入临界区
        while(flag[j]);           while(flag[i]);       // 等待特定进程放权
        // critical code          // critical code
        flag[i]=false;            flag[j]=false;
    Peterson算法：结合轮次法和双标志法后检查??
      Pi:                       Pj:
        flag[i]=true;             flag[j]=true;			// 宣言自己进入临界区
	trun=j;			  turn=i;
        while(flag[j]&&turn=j);	  while(flag[i]&&turn==i);	// 等待特定进程放权
        // critical code          // critical code
        flag[i]=false;            flag[j]=false;
  硬件实现
    中断屏蔽	CLI; /*critical code*/; SEI;
    硬件指令
      TestAndSet指令法
        // 全局变量lock初值为false，表示临界区空闲
        while(TestAndSet(&lock));	// TestAndSet表示置位并返回旧值
        // critical code
        lock=false;
      Swap指令法
        // 全局变量lock初值为false，表示临界区空闲
        key=true;			// 局部变量key
        while(key==true)
          Swap(&lock, &key);		// Swap表示交换两个变量
        end
        // critical code 
        lock=false;
信号量
  整型信号量
    wait(int S) {			signal(int S) {
      while(S<=0); //缺资源则忙等待	  S++;		//释放一个资源
      S--;         //拿走一个资源	}
    }
  记录型信号量
    typedef struct {
      int val;		 // 初值为资源数
      struct process *q; // 进程链表，链接所有等待此资源的进程
    } semphore;
    wait(semphore S) {				signal(semphore S) {
      S.val--;           // 预约一个资源	  S.val++;		// 释放一个资源
      if(S.val<0) {	 // 没拿到资源		  if(S.val<=0) {	// 仍有进程等待
        S.q->enQueue(P); // 本进程入队等待	    S.q->deQueue(P);	// 唤醒等待队列中的第一个进程
        block(P);				    wakeup(P);
      }						}
    }
    *注意S.val操作的先行性；S.value为正时表示剩余可用资源数，为负时表示等待队列长度
  信号量同步：等待协同进程运行到断点
    int S=0; // 最初缺资源
    P1() {			P2() {
      data=1;			  P(S); // 等待P1执行到断点
      V(S); //唤醒P2的等待	  print(data);
    }				}
  信号量前驱：多个协同进程拓扑排序
    1.设置进程数量N个0-1信号量，表示第i号进程是否执行完毕，初值为0
    2.进程i,j等必须后于进程p启动时，i/j中执行P(p);
    3.进程p执行完毕后通知其后继节点，p中执行V(Si);V(Sj);
  信号量互斥：互斥访问
    int S=1;	// 最初有一个资源
    Pi() {	// 若干个进程
      P(S);	// 拿到资源
      // critical code
      V(S);	// 归还资源
    }
管程
  定义：一个软件模块，定义了数据结构及其操作，能修改其中的数据与同步所管辖的进程
  组成：局部于管程共享数据结构的说明+对该数据结构的一组操作+初始化共享数据的语句
  基本特征
    1.管程的局部数据只能被管程的过程所访问
    2.进程只能通过调用管程内的过程才能访问共享数据
    3.每次仅允许一个进程在管程内执行某个内部过程
  经典同步问题
    生产者-消费者：两个进程共享有限缓冲区
      int mutex=1; // 访问缓冲区时的互斥
      int canProduce=n;
      int canConsume=0;
      producer() {		consumer() {
        P(canProduce);		  P(canConsume);
        P(mutex);		  P(mutex);
        // data -> buffer	  // buffer -> data
        V(mutex);		  V(mutex);
        V(canConsume);		  V(canProduce);
      }				}
    读者-写者：多个进程读多个进程写，读时可读不写/写时不读不写
      读进程优先版本
        int cntReader=0;
        int mutex=1;	// 更新cntReader时的互斥
        int rw=1;	// 读写时的互斥
        writer() {		reader() {
          P(rw);		  P(mutex);
          // write data		  if(cntReader==0) P(rw); // 第一个读者来了，锁住写
          V(rw);		  cntReader++;
        }			  V(mutex);
				  // read data
				  P(mutex);
				  if(cntReader==0) V(rw); // 末一个读者走了，释放写
				  cntReader--;
				  V(mutex);
				}
      读写进程公平版本
        int cntReader=0;
        int mutex=1;
        int rw=1;
        int w=1;	// 实现写优先
        writer() {              reader() {
          P(w);                   P(w);
          P(rw);                  P(mutex);
          // write date           if(cntReader==0) P(rw); // 第一个读者来了，锁住写
          V(rw);                  cntReader++;
          V(w);                   V(mutex);
        }                         V(w);   
                                  // read data
                                  P(mutex);
                                  if(cntReader==0) V(rw); // 末一个读者走了，释放写
                                  cntReader--;
                                  V(mutex);
                                }
    哲学家就餐
      int chopsticks[]={1, 1, 1, 1, 1};
      int mutex=1;
      Pi() {
        P(mutex);
        P(chopsticks[i]);
        P(chopsticks[(i+1)%5]);
        V(mutex);
        // eat
        V(chopsticks[i]);
        V(chopsticks[(i+1)%5]);
      }
    吸烟者：变种生产者-消费者问题
      int food=0;
      int drink=0;
      int canProduce=0;
      producer() {		needFood() {		needDrink() {
        if(rand()<0.5) V(food);	  P(food);		  P(drink);
        else V(drink);		  V(canProduce);	  V(canProduce);
        P(canProduce);		}			}
      }
5.死锁
必要条件=互斥访问+不可剥夺+请求保持+环路等待
处理策略
  ^		资源分配	策略			优点			缺点
  死锁预防	保守，宁可闲置	静态|顺序分配/资源剥夺	适合突发式处理的进程	效率低不灵活，进程初始化慢/剥夺过多
  死锁避免	保持安全则分配	稳定安全状态的序列	不必剥夺		必须预知将来所需资源，进程不能长时间阻塞
  死锁检测	空闲就分配	定期检查死锁存在	不耽搁初始化，JIT处理	强制剥夺解锁造成损失
死锁预防
  破坏互斥访问	所有资源共享使用，通常无法做到
  破坏不可剥夺	可能导致上一阶段工作失效，通常可用于寄存器/内存
  破坏请求保持	使用预先静态分配；会导致使用率低、饥饿
  破坏环路等待	资源编号、顺序分配，申请i号资源后不能再申请编号小于i的资源；限制了硬件扩展、编程思路
死锁避免
  安全状态
    对于调度队列中的所有进程，在当前资源分配状态下至少存在一个可推进序列，则称系统处于安全状态
    *处于安全状态一定不存在死锁，不安全状态可能会产生死锁
  银行家算法
    可用资源矢量Available
    程序最大需求矩阵Max
    当前资源分配矩阵Allocation
    需求矩阵Need[i,j]=Max[i,j]-Allcation[i,j]
    *对于某个资源请求R，尝试分配后寻找可推进序列，若存在则确认分配，否则回滚阻塞此请求
死锁检测
  资源分配图：圆形表示进程，矩形表示资源，有向边表示分配/请求情况
  死锁定理：S为死锁的充要条件是S不可拓扑排序
  死锁解除
    1.资源剥夺	挂起某些进程，剥夺其资源
    2.进程撤销	撤销某些进程，释放其资源
    3.进程回退	通知进程自愿释放资源并回滚，要求进程有还原点

二.内存管理
1.基础
内存管理概念
  功能：空间分配回收/地址转换/空间扩充/存储保护
  装入与链接
    编译：源代码转化为若干目标模块obj
    链接：目标模块及库函数链接成装入模块
      静态链接		执行前链接成一个整二进制
      装入时动态链接	装入时边装边链接
      运行时动态链接	需要某模块时，动态装入并链接
    装入：装入程序把可装入模块载入内存
      绝对装入		机器指令中的地址都是绝对地址；只适合单道程序系统
      可重定位装入	静态重定位，装入时修改每个目标模块指令中的地址以符合指定的装入地址
      动态运行装入	动态重定位，每条指令执行时才重定位其地址
  地址空间
    逻辑	每个目标模块中每条指令地址为相对于模块首(即0H)的地址，链接时重整为以0开始的线性地址空间
    物理	装入时实际放置的物理地址
  内存保护
    上下限寄存器	CPU访问地址时对比两个限寄存器的值
    基址+界地址/限长	默认以基址寄存器为最小合法地址，因此只比较偏移量是否超出界地址寄存器
覆盖/交换
  覆盖	(优化单个大程序)用户空间划分为固定区+覆盖区，以程序段为单位访问时才调入调出覆盖区；打破了程序必须装入所有段才能运行的限制
  交换	(优化程序间切换)阻塞进程移出内存到辅存交换区，腾出的内存可以换入交换区中休眠的就绪进程
连续分配方式
  单一连续	内存分为系统区+用户区、使用覆盖技术；适合单用户单任务，有内部碎片
  固定分区	用户区内存再分为固定大小的区域，维护分配表::=(分区编号, 大小KB, 首地址KB, 状态)；超大程序仍需用覆盖技术、有内部碎片
    分区等大	每个固定分区等大；适合控制多个相同对象的场合
    分区不等	较多小分区，较少大分区(如伙伴算法)；通常更加灵活
  动态分区	进程装入内存时划分适当的内存区域；有外部碎片(通过紧凑以解决)
    首次适应		空闲分区表按编号排序，从头查找分配第一个满足要求的分区；通常性能最好
    临近/循环首次适应	空闲分区表按编号排序，从上次分配处开始循环查找第一个满足要求的分区
    最佳适应		空闲分区链表按大小排序，分配最小而能满足要求的分区；性能差，外部碎片最多
    最坏/最大适应	空闲分区链表按大小排序，每次分配最大的分区；性能最差，经常缺大内存块
非连续分配方式
  基本分页：主存和进程都划分为若干相等大小的块，以块为主存的申请单位；无外部碎片，内部碎片小(平均半页)
    基本概念
      页面	进程块称为页，主存块称为页框，辅存块称为块；页大小应为2^k个字节(通常4KB)
      逻辑地址	地址::=(页号P, 页内偏移W)，P的位数暗示了页数上限(等于主存页框数)，W的位数暗示了页大小
      页表	进程::=(页号i, ...)，页表::=(页号, 页框号)，主存::=(页框号, 数据)；页表也在内存中，页号与页框号等长
    地址变换机构
      页表寄存器PTR::=(页表首地址F, 页表长度M)
      *取一个地址的数据需要两次访存
      0.每个进程拥有一个页表，进程非执行时，页表信息转储在PCB中；进程执行时，转储信息恢复到PTR中
      1.访问逻辑地址A时，计算页号P=A/L、页内偏移W=A%L，其中页大小为L
      2.判断是否P>=M发生越界中断，否则继续
      3.取Mem[页表首址F+页号P*页表项长度l]即得页框号b
      4.计算物理地址E=b*L+W
    快表/关联寄存器TLB
      1.根据逻辑地址计算页号，查高速缓存快表，命中则获得页框号，可直接计算物理地址访存一次
      2.不命中则查主存慢表，获得页框号后同时更新快表(使用一些淘汰算法)
    一级页表的问题：(32位地址/4KB页/4B页表项为例)
      1.占用全部内存地址空间(4GB)的程序需2^20页共计页表大小为4MB，这太大了?
      2.由于页面很小，因此大进程的页数很多，但当前频繁使用的页很少，因此也只需要很少的页表项，希望把不频繁使用的页表部分休眠到辅存
    两级页表
      逻辑地址	地址::=(页目录号10bit, 页号10bit, 页内偏移12bit)，这样划分可以使得页目录表和页表都可容纳1024个表项刚好4KB=一页
  基本分段
    基本概念
      分段	按程序自然段segment划分若干段
      逻辑地址	地址::=(段号S, 段内偏移W)，S的位数暗示了一个进程最多可被分段数，W的位数暗示了最大段长
      段表	段表::=(段号, 段长, 段首地址)
    地址变换机构
      段表寄存器::=(段表首地址F, 段表长度M)
      0.每个程序拥有一个段表，其转储恢复同页表
      1.地址转译同页表：先断言段号越界，查段表获取段基址，再断言偏移量越界，凑物理地址访存
    共享与保护
      共享：两个作业中的某个段表项指向同一个物理段：可修改的共享段应有锁访问机制，不可修改的纯代码段称为可重入代码
  段页式
    段表	段表::=(段号, 段长, 段首地址)，每个进程一个段表
    页表	页表::=(页号, 页首地址)，每个段一个页表
    逻辑地址	地址::=(段号, 页号, 页内偏移)；需要架构支持段表寄存器

2.虚拟内存
基本概念
  传统存储管理特征
    一次性	作业必须一次性全部装入内存才能运行；可能导致大作业无法运行、多道程序时饥饿
    驻留性	作业载入内存后直到退出前任何一部分都不会换出内存
  局部性原理
    时间	同一条指令/数据在短时间被反复执行/访问
    空间	下一个执行的指令/访问的数据通常在当前的临近区域
  虚拟存储器特征
    多次性	允许一个程序分成多次调入内存
    兑换新	允许程序运行期间被换入换出内存
    虚拟性	逻辑上的内存容量大于实际物理内存容量
  技术实现
    方式：请求分页/请求分段/请求段页
    硬件支持：一定容量内外存/页表或段表机制/中断机构处理缺页/地址变换机构
请求分页方式
  页表机制
    页表项::=(页号, 页框号, 状态位P, 访问字段A, 修改位M, 外存地址)
      状态位P	该页是否有效，已载入内存
      访问字段M	记录访问次数或寿命，供换页算法使用
      修改位M	该页调入内存后是否被修改过
      外存地址	通常是外存物理块号
  缺页中断
    0.所请求的页面无效时产生缺页中断(内部中断，一条指令可能产生多个缺页中断)
    1.操作系统响应缺页中断，阻塞缺页的进程
    2.在内存中申请一个空白页框并通知IO调入物理块；若无空白页则需按算法淘汰一个旧页
    3.调页完成后唤醒缺页进程
  地址变换
    0.请求访问某个页中的内容
    1.断言页号越界，查高速缓存快表取页框号、凑地址访存结束
    2.查内存页表取页框号、更新快表、凑地址访存结束
    3.发现页框号无效，产生缺页中断
      ISR切入
      1.在外存中找到缺的物理块
      2.在内存中申请空白页框，申请失败则换出一页(若有改动需回写)
      3.启动I/O将物理块写入到空白页框
      4.修改页表记录，设置有效位
    4.回到步骤2
页面置换算法
  最佳OPT		淘汰以后永不使用或最长时间不使用的页；实际无法实现，可作为评估模型
  先进先出FIFO		淘汰载入以来年龄最老的页；队列类算法
    *Belady异常：分配页框数越多缺页故障越多的现象，只有FIFO会产生
  最近最久未使用LRU	淘汰距离上次访问最久远的页；需要硬件支持寄存器和栈的堆栈类算法(永不可能Belady异常)
  时钟CLOCK/最近未使用NRT
    0.每个页框增加一个使用位u，首次载入以及每次被访问时置1
    1.页框连接成循环链表，每次从上次停止位置继续扫描，把u=1的页u清零，直到遇到第一个u=0的页并将其换出
  改进型CLOCK
    0.每个页框增加一个使用位u和修改位m
    1.从上次停止位置继续扫描，遇到第一个u=0/m=0的页换出
    2.若1失败，重新扫面寻找u=0/m=1的页换出，其间跳过的页设置u=0
    3.若2失败，则此时所有页都有u=0，重复步骤1、仍然失败则重复步骤2
页面分配策略
  驻留集大小：给每个进程分配多少页的主存空间
    固定分配局部置换	每个进程分配指定的页框数，缺页时只能从这些页框中换
    可变分配全局置换	每个进程预分配一些页框，系统保留一个空闲页框表，缺页时系统填页后补发给进程
    可变分配局部置换	每个进程预分配一些页框，系统监控每个进程的缺页率决定是否补发/回收页框
  调入页面时机
    预调页策略		调页时一次性调入多个临近的页；目前预测准确率低，通常用户首次调页时程序员指定调入哪些页
    请求调页策略	缺页时触发中断，系统处理；每次只能调一个页
  何处调入页面
    对换空间足够	从对换区调入调出所有页面(交换分区用连续分配读写效率优于文件分区)
    兑换空间匮乏	需修改的页从交换区换入换出，不修改的页从文件区读出
    UNIX方式		未运行过的页面从文件区调入，运行过的页面换出至交换区以备下次换入；共享页面若被其他进程调入过则无需再调入
抖动：刚换出换入的页又需要被换入换出；通常原因是该进程所需频繁访问的页数量大于驻留集的可用页框数
工作集/驻留集
  0.指一段时间内进程所需要访问的页面集合
  1.通常操作系统监控评估进程的平均工作集大小以决定页框分配
  2.如果空闲页框不足以支撑某进程的工作集大小，系统可以暂停该进程放置抖动，直到可以补发空闲页框
地址翻译
  0.逻辑地址->查快表TLB获取页框号||->查页表获取页框号
  1.页框有效则拼接出物理地址，页框无效触发缺页中断
  2.物理地址->查Cache获取数据||->查内存获取数据
  虚拟地址::=(虚拟页号, 页内偏移)
    虚拟页号::=(TLB标记, TLB组索引)
  物理地址::=(物理页号, 页内偏移)
    物理页号::=(Cache标记)
    页内偏移::=(Cache组索引, Cache行内偏移)

三.文件管理
1.基本概念
概念
  定义		输入输出的单位
  属性		名称/标识符/类型/位置/大小/保护/时间日期用户标识
  基本操作	创建/写/读/重定位|寻址/删除/截断(保留属性、删除内容)
  打开文件表：系统维护一个
    文件指针		跟踪当前位置(上次读写位置)
    文件打开计数	计数为0时，系统关闭文件写入磁盘删除FCB条目
    文件磁盘位置	修改数据时需要读取该信息
    访问权限		打开文件时的访问字(r/w/a|+)，便于系统筛选I/O请求
逻辑结构
  无结构/流	以字节为单位，搜索通常只能穷举
  有结构/记录
    顺序文件：定长或变长的记录以连续地址或链表存储
      串结构	记录无序，后来者追加
      顺序结构	所有记录按关键字排序
    索引文件：引入索引表，指向目标文件首地址；索引表本身为定长顺序文件
    索引顺序文件：若干顺序文件分组，按组编制索引(前向星)
    直接/散列文件：文件的哈希值决定文件的物理地址
目录结构
  文件控制块FCB：实现按名称存取，(FCB一般64Byte)
    *一个FCB对应一个文件，一组FCB集合为文件总目录
    基本信息	文件名/文件物理位置/文件逻辑结构/文件物理结构
    存取控制	文件权限
    使用信息	建立时间/修改时间
  索引节点i-Node：从FCB中抽取文件名附上i节点编号，以加快文件查找
    *UNIX文件目录表::=(文件名:14Byte, i-Node指针: 2Byte) => 每个文件占用16Byte，比纯FCB轻量
    文件主标志符	文件拥有者/组的标志符
    文件类型		普通文件/目录/特殊(设备/管道)
    文件存取权限	ACL掩码
    文件物理地址	含有13个地址项(iaddr0~iaddr12)，直接或间接地给出文件内容所在磁盘块号
    文件长度		以字节为单位
    文件链接计数	系统中指向这个i-Node的硬链接计数
    文件存取时间	最近被进程存取的时间、索引节点最近被修改的时间
    *文件被打开时，i-Node信息复制到内存，并在内存索引节点副本中加入下列字段：
      索引节点编号	用于标志内存索引节点
      状态		指示此节点是否上锁/被修改
      访问计数		进程访问此节点时+1，访问结束-1
      逻辑设备号	所属文件系统的逻辑设备号
      指针链接		设置分别指向空闲链表和散列队列的指针
  目录结构
    *操作：搜索/创建文件/删除文件/显示目录/修改目录
    单级	系统建立一张目录表，每个文件占一个目录项
    两级	以用户为单位分为两级=主文件目录+用户文件目录
    多级	树状多级目录，对文件的访问从"当前目录"开始计算
    无环图	基于树而增加用于共享的硬链接，需要引入链接计数
文件共享
  基于索引节点/硬链接	两个用户A、B在各自的文件目录表中引用同一个i-Node，被引用i-Node需记录引用数
  基于符号链/软链接	用户A在自己的文件目录表里新建一个LINK类型文件，此文件包含被引用的路径名；循链会多次读盘效率低
文件保护
  访问类型	读/写/执行/添加/删除/列表清单/重命名/复制/编辑/...
  访问控制ACL	精简访问列表(拥有者-组-其他)/口令(身份核查)/密码(文件加密)

2.文件系统实现
层次结构
  用户调用接口	新建/打开/读写/关闭/删除文件+新建/删除目录的系统调用
  文件目录系统	管理活跃文件目录表、读写状态信息表、进程打开文件表、管理文件目录结构
  存取控制验证	用户访问请求按照FCB中的掩码过滤
  逻辑文件系统	将要读写的逻辑记录转化为逻辑结构内的块号(此层也开设文件信息缓冲区)
  物理文件系统	将逻辑记录所在块号转化为实际物理地址
  分配模块	负责分配回收辅存空间
  设备管理程序	设备分配、缓冲区分配、磁盘调度、设备启动、设备中断处理、缓冲区释放、设备释放
目录实现
  *目录操作频繁而费时，通常都会把当前使用的目录表复制到内存便于处理
  线性列表	目录表::=(文件名, 首数据块指针)，可用顺序表/链表实现
  哈希表	根据文件名哈希值算出在表中的指针偏移，操作快但要处理冲突
文件实现
  文件分配方式
    连续分配	目录项::=(文件名, 首块号, 块数长度)
      文件占用连续的物理块；可顺序/直接访问，但会产生外部碎片
    链接分配
      隐式链接	目录项::=(文件名, 首块号, 尾块号), 文件块::=(数据区, 下一块号)
        文件块构成链表；块损坏可能会导致断链
      显式链接	目录项::=(文件名, 首块号)，FAT表::=(块号, 下一块号)
        即把分散于文件块中的下指针集中保存于文件分配表FAT中
    索引分配	目录项::=(文件名, 索引块号)，索引块::=(数据块号i, ...)
      每个文件分配一个索引块，可通过查索引直接访问文件的第k块；索引占用太多空间
  文件存储空间管理
    空间初始化
      文件卷	磁盘的一部分或者整个磁盘，甚至多个磁盘
      格式化	划分文件区(数据块空间)、目录区(FCB空间)，建立空闲空间管理表、存放逻辑卷元信息的超级快
    空间管理
      空闲表	空闲盘块表::=(ID, 首空闲块号, 空闲块数)，基于连续分配而类似于内存分段
      空闲链表	把空闲盘块(或连续的盘区)链接起来，分配时依次从链首摘节点
      位图	用一个0-1位图来标志磁盘每个块的空闲状态
      成组链接	把第1~k号空闲盘块号保存在第0号磁盘，然后把第k+1~2*k号保存在第k号磁盘，以此类推

3.磁盘组织管理
  结构：磁盘=盘面*磁道*扇区，扇区即基本读写单位盘块(通常512B)
  性能指标
    *总平均存取时间Ta=(m*n+s)+1/(2r)+b/(rN)
    寻道时间Ts=m*n+s
      磁头移动到目标磁道所需时间：启动磁臂时间s(通常2ms)/跳过n个磁道/磁道间移动时间m(通常0.2ms)
    延迟时间Tr=1/(2r)	
      磁头移动到目标扇区所需时间，通常取半转：磁盘转速r(通常5400r/min)
    传输时间Tt=b/(rN)
      从磁盘读出b个字节的时间：读写字节数b/一个磁道含N个字节/磁盘转速r
  调度算法
    优化寻道时间
      先来先服务FCFS		时间早的优先，接近于随机调度
      最短寻找时间优先SSTF	优先选择距离当前磁头所在磁道最近的请求；局部频繁访问会导致饥饿
      扫描/电梯SCAN/LOOK		优先选择当前移动方向上距离当前磁头所在磁道最近的请求；双向扫描，局部性差于FCFS和SSTF
      循环扫描C-SCAN/C-LOOK	同扫描，但是强制规定单向
        *LOOK是SCAN的改进版，只需扫描到两侧最远端的一个请求即可返回磁头，不需强制到达磁盘边缘
    优化传输延迟
      多盘面错位编号，单盘上奇偶交叉，多盘重叠时错开一定的角度：磁盘读写一个块后需要一些整理时间才能再次读写
      *例如4个盘面重叠时四个象限分别编号：(1,3,2,4) (3,2,4,1) (2,4,1,3) (4,1,3,2)
  管理
    初始化
      物理格式化	划分扇区，扇区::=(头部, 数据区512B, 尾部)，保留一些备用扇区
      逻辑格式化	划分文件区/目录区，建立目录表、空闲区表等管理信息
    引导块：启动块一般位于0号磁道0号扇区，由BIOS引导以启动程序
    坏块：(IDE)FAT表中标记不使用，(SCSI)控制器维护一个磁盘坏块链表

四.输入输出I/O管理
1.I/O概述
设备分类
  使用特性	人机交互类/存储/网络通信
  传输速率	低速(键盘鼠标)/中速(打印机)/高速(磁带磁盘光盘)
  交换单位	块设备(磁盘)/字符设备(终端/打印机)
控制方式
  程序直接控制	CPU轮询IO设备状态(忙等待)
  中断驱动
    1.CPU发出IO指令后切换到其他进程，直到收到中断并处理中断后再返回原程序
    2.IO控制器收到IO指令并读写完设备后发出中断请求，听到CPU的取数据请求后把数据放上总线
  DMA
    特点
	  1.基本单位是数据块
	  2.数据传输在内存和设备间，不经过CPU
	  3.DMA的开始配置和结束处理时需CPU干涉，除此之外都由DMA控制器处理，并占用系统总线
    控制器组成
	  命令/状态寄存器CR		接收来自CPU的IO命令和控制信息
	  内存地址寄存器MAR		目标块起始地址
	  数据寄存器DR			暂存要传送的字
	  数据计数器DC			本次需传送的字数
  通道控制
    1.要完成一组块的读写和控制，CPU只需向通道控制器发出一条IO指令
	2.通道控制程序在内存中，相当于把DMA中启动传输时CPU的配置过程存储化了交给通道去完成
层次结构
  用户层IO软件		需要读写存储的用户软件
  设备独立性软件	操作系统封装出来的系统设备和IO操作函数
  设备驱动程序		操作系统到设备控制器之间的协调通信
  中断处理程序		负责切换进程、测试中断源
  硬件设备			控制器以及多个物理存储设备

2.I/O核心子系统
提供服务：I/O调度、缓冲/高速缓存、设备分配/回收/保护、假脱机、差错处理
I/O调度：维护调整请求队列的顺序，以优化系统整体性能
高速缓存与缓冲区
  磁盘高速缓存Cache
    1.在内存中开辟一个大小固定的区域，作为对磁盘的缓存
	2.把内存中未用的区域作为缓冲池，供分页系统和磁盘I/O时共享
  缓冲区Buffer
    目的：缓和CPU和I/O速度不匹配问题增加并行性，缓和数据单位不一致问题，减少CPU中断频率
    实现：硬件缓冲器(成本高)；内存缓冲区
    分类
	  单缓冲	Ts=M+max(C, T)
      双缓冲	Td=max(C, T)
      循环缓冲	单向缓冲；循环使用的队列，需要维护in/out指针
      缓冲池	双向缓冲；维护三个队列(空缓冲块队列/输出队列/输入队列)，以及各队列的指针
  Cache/Buffer对比
    缓存：高速设备先访问缓存，若不命中则访问低速设备；存放的是低速设备的数据备份
	缓冲：必须经过的管道中介，高速设备永远不会直接访问低速设备
设备分配回收
  方式：独占式/分时共享/SPOOLing方式
  控制表数据结构
    系统设备表SDT		[整个系统一张]
	  设备类/设备标识符/设备控制表DCT/驱动程序入口
    设备控制表DCT		[每个设备一张]
	  标识符/设备类型/设备状态/所属控制器的指针/执行次数或时间/设备队列首指针
	控制器控制表COCT	[每个控制器一张]
	  标识符/控制器状态/所连接的通道表指针/控制器队列首尾指针
	通道控制表CHCT		[每个通道一张]
	  标识符/通道状态/所连接的控制器表指针/通道队列首尾指针
  策略
    静态分配	作业开始前一次性分配完所需的全部设备，并占用直到作业完成
	动态分配	作业运行中申请时分配对应设备，用完立刻释放
  安全性
    安全分配	进程发出I/O请求后被阻塞，即不能申请多个资源
	不安全分配	可以申请若干设备，直到某设备申请失败时才阻塞
  逻辑-物理设备映射
    逻辑设备表LUT：整个系统/每个用户一张，程序用逻辑设备名请求I/O，系统查LUT表以找物理设备和驱动程序
SPOOLing/假脱机技术
               | 输入/输出控制进程Pi/Po |
    输入设备-->|       输入缓冲Bi       |-->| 输入井 |
	输出设备<--|       输出缓冲Bo       |<--| 输出井 |
  输入/输出井		磁盘开辟两个存储区域：输入井收容I/O设备输入，输出井收容用户程序输出
  输入/输出缓冲区	内存开辟两个缓冲区：输入缓冲暂存输入设备数据且稍后送入输入井，输出缓冲暂存输出井传来的数据且稍后送入输出设备
  输入/输出进程		两个进程模拟分别外围控制机把输入井数据压入输入缓冲/输输出缓冲压入输出井
    *独占设备改造为共享设备(比如打印机)
	   0.SPOOLing系统获取设备的控制权
	   1.用户程序申请该设备时并不分配设备，而是如下
	   2.1输入控制进程收集输入设备的数据投入输入井
	   2.2输出控制进程吐出输出井的数据到输出设备
